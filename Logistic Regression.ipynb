{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6-wA1q3G3Hy",
        "outputId": "ed1ec716-17cd-4927-b198-7e34c6fc9883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSIurpCbHLPf",
        "outputId": "968652e2-3663-44c6-83d7-8ff5842a95e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sentiment                                               text\n",
            "0  Negative               Enna da ellam avan seyal  Mari iruku\n",
            "1  Negative          This movei is just like  ellam avan seyal\n",
            "2  Positive  Padam vanthathum 13k dislike pottavaga yellam ...\n",
            "3  Positive    Neraya neraya neraya... ... V era level...thala\n",
            "4  Positive  wow thavala sema mass....padam oru pundaikum a...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('cleaned_tweets_with_emojis.csv')\n",
        "\n",
        "# Column fix\n",
        "if 'Tweet' in df.columns:\n",
        "    df = df.rename(columns={'Tweet': 'text'})\n",
        "if 'label' in df.columns and 'sentiment' not in df.columns:\n",
        "    df = df.rename(columns={'label': 'sentiment'})\n",
        "if 'text' not in df.columns:\n",
        "    print(\"ERROR: No 'text' column found!\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c57ea402",
        "outputId": "7e821521-0bcb-4429-c2a0-7f0b82c9a382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sentiment                                               text  \\\n",
            "0  Negative               Enna da ellam avan seyal  Mari iruku   \n",
            "1  Negative          This movei is just like  ellam avan seyal   \n",
            "2  Positive  Padam vanthathum 13k dislike pottavaga yellam ...   \n",
            "3  Positive    Neraya neraya neraya... ... V era level...thala   \n",
            "4  Positive  wow thavala sema mass....padam oru pundaikum a...   \n",
            "\n",
            "                                          clean_text  \n",
            "0                   enna ellam avan seyal mari iruku  \n",
            "1                        movei like ellam avan seyal  \n",
            "2  padam vanthathum dislike pottavaga yellam yea ...  \n",
            "3                neraya neraya neraya era levelthala  \n",
            "4   wow thavala sema masspadam oru pundaikum aagathu  \n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "emoji_sentiment = {\"ğŸ˜Š\":\"HAPPY\", \"ğŸ˜\":\"LOVE\", \"ğŸ˜¢\":\"SAD\", \"ğŸ˜¡\":\"ANGRY\", \"ğŸ˜‚\":\"JOY\", \"ğŸ˜­\":\"SAD\", \"ğŸ˜”\":\"SAD\", \"â¤ï¸\":\"LOVE\"}\n",
        "stopword_list = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(Tweet):\n",
        "    # Keep words and specified emojis (edit allowed_emojis for your full emoji set)\n",
        "    allowed_emojis = \"ğŸ˜ŠğŸ˜ğŸ˜¢ğŸ˜¡ğŸ˜‚ğŸ˜­ğŸ˜”â¤ï¸\"\n",
        "    Tweet = str(Tweet).lower()\n",
        "    Tweet = re.sub(r\"http\\S+|www\\S+\", \"\", Tweet)\n",
        "    Tweet = re.sub(r\"@\\w+|#\\w+\", \"\", Tweet)\n",
        "    # Only remove non-alphabetic (except emojis you care about)\n",
        "    Tweet = re.sub(r\"[^a-z\\s\" + allowed_emojis + \"]\", \"\", Tweet)\n",
        "    words = Tweet.split()\n",
        "    words = [word for word in words if word not in stopword_list and len(word) > 2]\n",
        "    return \" \".join(words)\n",
        "# Re-create df['clean_text']\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "\n",
        "# Apply cleaning\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "077c3d51",
        "outputId": "a492e53f-4b53-4669-ffcd-fab422d716dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mixed_feelings' 'Negative' 'Positive' 'not-Tamil' 'unknown_state']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label\"] = le.fit_transform(df[\"Sentiment\"])\n",
        "print(le.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8hhBYCtHLqk",
        "outputId": "2cd8f5a7-6eed-4d38-cbff-0795b100ec8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mixed_feelings' 'Negative' 'Positive' 'not-Tamil' 'unknown_state']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced class distribution: 1    9992\n",
            "2    9992\n",
            "0    9992\n",
            "3    9992\n",
            "4    9992\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"label\"] = le.fit_transform(df[\"Sentiment\"])\n",
        "print(le.classes_)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def emoji_word_tokenizer(text):\n",
        "    return re.findall(r'\\w+|[ğŸ˜ŠğŸ˜ğŸ˜¢ğŸ˜¡ğŸ˜‚ğŸ˜­ğŸ˜”â¤ï¸]', text)\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    tokenizer=emoji_word_tokenizer,\n",
        "    max_features=8000,\n",
        "    ngram_range=(1,2)\n",
        ")\n",
        "X = vectorizer.fit_transform(df[\"clean_text\"])\n",
        "y = df[\"label\"].values\n",
        "\n",
        "# SMOTE and rest as before\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=3)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "print(\"Balanced class distribution:\", pd.Series(y_res).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res\n",
        ")\n",
        "# Try much higher C, remove regularization penalty\n",
        "logreg = LogisticRegression(\n",
        "    solver='saga',\n",
        "    multi_class='multinomial',\n",
        "    max_iter=10000,\n",
        "    C=50.0,\n",
        "    penalty=None,\n",
        "    class_weight={0:0.8, 1:1.0, 2:1.2, 3:1.0, 4:1.0},  # Example: 0=Mixed_feelings, 1=Negative, 2=Positive, etc.\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f'Logistic Regression Accuracy: {acc * 100:.2f}%')\n",
        "print(f'Weighted F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred, digits=4, target_names=list(le.classes_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnPQd6r8UPNh",
        "outputId": "ee44ec0a-6c71-4760-d94a-17dfa45c909d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 90.23%\n",
            "Weighted F1 Score: 0.8967\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings     0.8520    0.9505    0.8986      1999\n",
            "      Negative     0.8717    0.9520    0.9100      1998\n",
            "      Positive     0.9516    0.6296    0.7578      1998\n",
            "     not-Tamil     0.9331    0.9985    0.9647      1999\n",
            " unknown_state     0.9250    0.9810    0.9521      1998\n",
            "\n",
            "      accuracy                         0.9023      9992\n",
            "     macro avg     0.9067    0.9023    0.8967      9992\n",
            "  weighted avg     0.9067    0.9023    0.8967      9992\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2JQVWVuHcf3",
        "outputId": "27c8bf7a-3477-4caf-d6ac-d63e60d71d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Nalla padam da sema feel varuthu ğŸ˜Š\n",
            "Predicted Sentiment: Mixed_feelings\n",
            "Predicted Emotion: HAPPY\n",
            "--------------------------------------------------\n",
            "Text: Intha trailer mokka da ğŸ˜¢\n",
            "Predicted Sentiment: Negative\n",
            "Predicted Emotion: SAD\n",
            "--------------------------------------------------\n",
            "Text: Super movie da love it ğŸ˜\n",
            "Predicted Sentiment: Positive\n",
            "Predicted Emotion: LOVE\n",
            "--------------------------------------------------\n",
            "Text: Ippadiye poguthu mass ğŸ˜‚\n",
            "Predicted Sentiment: Mixed_feelings\n",
            "Predicted Emotion: JOY\n",
            "--------------------------------------------------\n",
            "Text: Worst padam thalaiva ğŸ˜¡\n",
            "Predicted Sentiment: Mixed_feelings\n",
            "Predicted Emotion: ANGRY\n",
            "--------------------------------------------------\n",
            "Text: Konjam Irumugan Madhiri irukku....All the best.....team..\n",
            "Predicted Sentiment: Mixed_feelings\n",
            "Predicted Emotion: Neutral\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def hardcode_correction(text, pred_sentiment, pred_emotion, probas=None):\n",
        "    # Emoji-based correction\n",
        "    if any(e in text for e in [\"ğŸ˜Š\",\"ğŸ˜\",\"ğŸ˜‚\"]):\n",
        "        if pred_sentiment == \"Mixed_feelings\":\n",
        "            return \"Positive\", pred_emotion\n",
        "    if any(e in text for e in [\"ğŸ˜¡\",\"ğŸ˜¢\"]):\n",
        "        if pred_sentiment == \"Mixed_feelings\":\n",
        "            return \"Negative\", pred_emotion\n",
        "\n",
        "    # Text-only (no emojis), optionally use probabilities if available\n",
        "    if probas is not None and pred_sentiment == \"Mixed_feelings\":\n",
        "        max_proba = max(probas)\n",
        "        max_idx = probas.index(max_proba)\n",
        "        idx2label = {0:\"Mixed_feelings\", 1:\"Negative\", 2:\"Positive\"}  # adjust as per your label order\n",
        "        # If model is confident about Positive/Negative, override Mixed_feelings\n",
        "        if max_proba > 0.60 and max_idx in [1,2]:\n",
        "            return idx2label[max_idx], pred_emotion\n",
        "    return pred_sentiment, pred_emotion\n",
        "\n",
        "test_texts = [\n",
        "    \"Nalla padam da sema feel varuthu ğŸ˜Š\",\n",
        "    \"Intha trailer mokka da ğŸ˜¢\",\n",
        "    \"Super movie da love it ğŸ˜\",\n",
        "    \"Ippadiye poguthu mass ğŸ˜‚\",\n",
        "    \"Worst padam thalaiva ğŸ˜¡\",\n",
        "    \"Konjam Irumugan Madhiri irukku....All the best.....team..\"\n",
        "]\n",
        "for txt in test_texts:\n",
        "    predict_sentiment_and_emotion(txt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}